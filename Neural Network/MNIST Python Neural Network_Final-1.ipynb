{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer (Linear Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Linear():\n",
    "    def __init__(self, in_size, out_size):\n",
    "        self.W = np.random.randn(in_size, out_size) * 0.01\n",
    "        self.b = np.zeros((1, out_size))\n",
    "        self.params = [self.W, self.b]\n",
    "        self.gradW = None\n",
    "        self.gradB = None\n",
    "        self.gradInput = None        \n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        self.output = np.dot(X, self.W) + self.b\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradW = np.dot(self.X.T, nextgrad)\n",
    "        self.gradB = np.sum(nextgrad, axis=0)\n",
    "        self.gradInput = np.dot(nextgrad, self.W.T)\n",
    "        return self.gradInput, [self.gradW, self.gradB]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectified Linear Activation Layer (ReLU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        self.gradInput = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.output = np.maximum(X, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, nextgrad):\n",
    "        self.gradInput = nextgrad.copy()\n",
    "        self.gradInput[self.output <=0] = 0\n",
    "        return self.gradInput, []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the Cross Entropy Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropy:\n",
    "    def forward(self, X, y):\n",
    "        self.m = y.shape[0]\n",
    "        self.p = softmax(X)\n",
    "        cross_entropy = -np.log(self.p[range(self.m), y])\n",
    "        loss = cross_entropy[0] / self.m\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        y_idx = y.argmax()        \n",
    "        grad = softmax(X)\n",
    "        grad[range(self.m), y] -= 1\n",
    "        grad /= self.m\n",
    "        return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
    "\n",
    "\n",
    "train_features = train_features.reshape(60000, 784)\n",
    "print(train_features.shape)\n",
    "test_features = test_features.reshape(10000, 784)\n",
    "print(test_features.shape)\n",
    "\n",
    "\n",
    "# # normalize inputs from 0-255 to 0-1\n",
    "train_features = train_features / 255.0\n",
    "test_features = test_features / 255.0\n",
    "\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)\n",
    "\n",
    "X_train = train_features\n",
    "y_train = train_targets\n",
    "\n",
    "X_val = test_features\n",
    "y_val = test_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we define the container NN class that enables the forward prop and backward propagation of the entire network. Note, how this class enables us to add layers of different types and also correctly pass gradients using the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "    def __init__(self, lossfunc=CrossEntropy()):\n",
    "        self.params = []\n",
    "        self.layers = []\n",
    "        self.loss_func = lossfunc\n",
    "        self.grads = []\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "        self.params.append(layer.params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        for layer in self.layers:\n",
    "            X = layer.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def backward(self, nextgrad):\n",
    "        self.clear_grad_param()\n",
    "        for layer in reversed(self.layers):\n",
    "            nextgrad, grad = layer.backward(nextgrad)\n",
    "            self.grads.append(grad)\n",
    "        return self.grads\n",
    "    \n",
    "    def train_step(self, X, y):\n",
    "        out = self.forward(X)\n",
    "        loss = self.loss_func.forward(out,y)\n",
    "        nextgrad = self.loss_func.backward(out,y)\n",
    "        grads = self.backward(nextgrad)\n",
    "        return loss, grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self.forward(X)\n",
    "        return np.argmax(X, axis=1)\n",
    "    \n",
    "    def predict_scores(self, X):\n",
    "        X = self.forward(X)\n",
    "        return X\n",
    "    \n",
    "    def clear_grad_param(self):\n",
    "        self.grads = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the update function (SGD with momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(velocity, params, grads, learning_rate=0.01, mu=0.9):\n",
    "    for v, p, g, in zip(velocity, params, reversed(grads)):\n",
    "        for i in range(len(g)):\n",
    "            v[i] = mu * v[i] + learning_rate * g[i]\n",
    "            p[i] -= v[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function which gives us the minibatches (both the datapoint and the corresponding label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get minibatches\n",
    "def minibatch(X, y, minibatch_size):\n",
    "    n = X.shape[0]\n",
    "    minibatches = []\n",
    "    permutation = np.random.permutation(X.shape[0])\n",
    "    X = X[permutation]\n",
    "    y = y[permutation]\n",
    "    \n",
    "    for i in range(0, n , minibatch_size):\n",
    "        X_batch = X[i:i + minibatch_size, :]\n",
    "        y_batch = y[i:i + minibatch_size, ]\n",
    "        minibatches.append((X_batch, y_batch))\n",
    "        \n",
    "    return minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The traning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, X_train, y_train, minibatch_size, epoch, learning_rate, mu=0.9, X_val=None, y_val=None):\n",
    "    val_loss_epoch = []\n",
    "    minibatches = minibatch(X_train, y_train, minibatch_size)\n",
    "    minibatches_val = minibatch(X_val, y_val, minibatch_size)\n",
    "\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        loss_batch = []\n",
    "        val_loss_batch = []\n",
    "        velocity = []\n",
    "        for param_layer in net.params:\n",
    "            p = [np.zeros_like(param) for param in list(param_layer)]\n",
    "            velocity.append(p)\n",
    "            \n",
    "        # iterate over mini batches\n",
    "        for X_mini, y_mini in minibatches:\n",
    "            loss, grads = net.train_step(X_mini, y_mini)\n",
    "            loss_batch.append(loss)\n",
    "            update_params(velocity, net.params, grads, learning_rate=learning_rate, mu=mu)\n",
    "\n",
    "        for X_mini_val, y_mini_val in minibatches_val:\n",
    "            val_loss, _ = net.train_step(X_mini, y_mini)\n",
    "            val_loss_batch.append(val_loss)\n",
    "        \n",
    "        # accuracy of model at end of epoch after all mini batch updates\n",
    "        m_train = X_train.shape[0]\n",
    "        m_val = X_val.shape[0]\n",
    "        y_train_pred = np.array([], dtype=\"int64\")\n",
    "        y_val_pred = np.array([], dtype=\"int64\")\n",
    "        y_train1 = []\n",
    "        y_vall = []\n",
    "        for i in range(0, m_train, minibatch_size):\n",
    "            X_tr = X_train[i:i + minibatch_size, : ]\n",
    "            y_tr = y_train[i:i + minibatch_size,]\n",
    "            y_train1 = np.append(y_train1, y_tr)\n",
    "            y_train_pred = np.append(y_train_pred, net.predict(X_tr))\n",
    "\n",
    "        for i in range(0, m_val, minibatch_size):\n",
    "            X_va = X_val[i:i + minibatch_size, : ]\n",
    "            y_va = y_val[i:i + minibatch_size,]\n",
    "            y_vall = np.append(y_vall, y_va)\n",
    "            y_val_pred = np.append(y_val_pred, net.predict(X_va))\n",
    "            \n",
    "        train_acc = check_accuracy(y_train1, y_train_pred)\n",
    "        val_acc = check_accuracy(y_vall, y_val_pred)\n",
    "\n",
    "        mean_train_loss = sum(loss_batch) / float(len(loss_batch))\n",
    "        mean_val_loss = sum(val_loss_batch) / float(len(val_loss_batch))\n",
    "        \n",
    "        val_loss_epoch.append(mean_val_loss)\n",
    "        print(\"Loss = {0} | Training Accuracy = {1} | Val Loss = {2} | Val Accuracy = {3}\".format(mean_train_loss, train_acc, mean_val_loss, val_acc))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the accuracy of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(y_true, y_pred):\n",
    "    return np.mean(y_pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Invoking all that we have created until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss = 0.0023549048771502514 | Training Accuracy = 0.94355 | Val Loss = 0.011006748288062656 | Val Accuracy = 0.9418\n",
      "Loss = 0.000872891531522087 | Training Accuracy = 0.9581 | Val Loss = 0.006734355248797491 | Val Accuracy = 0.9515\n",
      "Loss = 0.0006478242463078108 | Training Accuracy = 0.9657333333333333 | Val Loss = 0.004019310792557969 | Val Accuracy = 0.9576\n",
      "Loss = 0.0005110822538505272 | Training Accuracy = 0.9703833333333334 | Val Loss = 0.002599764690663141 | Val Accuracy = 0.9612\n",
      "Loss = 0.0004925764972407016 | Training Accuracy = 0.9733333333333334 | Val Loss = 0.0019425537657163235 | Val Accuracy = 0.9635\n",
      "Loss = 0.0004654604503818383 | Training Accuracy = 0.9754 | Val Loss = 0.0013616309669361804 | Val Accuracy = 0.9651\n",
      "Loss = 0.0004450213785366022 | Training Accuracy = 0.9782 | Val Loss = 0.0008239601430697143 | Val Accuracy = 0.9659\n",
      "Loss = 0.0003942328274402805 | Training Accuracy = 0.97915 | Val Loss = 0.0002937260455949889 | Val Accuracy = 0.9664\n",
      "Loss = 0.00037007307445317746 | Training Accuracy = 0.97985 | Val Loss = 0.00024446559309801213 | Val Accuracy = 0.9678\n",
      "Loss = 0.0003347447957103502 | Training Accuracy = 0.9809333333333333 | Val Loss = 9.48330017348526e-05 | Val Accuracy = 0.9677\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "\n",
    "## input size\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "## hyperparameters\n",
    "iterations = 10\n",
    "learning_rate = 0.1\n",
    "hidden_nodes = 32\n",
    "output_nodes = 10\n",
    "\n",
    "## define neural net\n",
    "nn = NN()\n",
    "nn.add_layer(Linear(input_dim, hidden_nodes))\n",
    "nn.add_layer(ReLU())\n",
    "nn.add_layer(Linear(hidden_nodes, output_nodes))\n",
    "\n",
    "nn = train(nn, X_train , y_train, minibatch_size=200, epoch=10, \\\n",
    "           learning_rate=learning_rate, X_val=X_val, y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fprop a single image and showing its prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1769291850>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[0].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Scores for each class\n",
    "prediction = nn.predict_scores(X_val[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores\n",
      "[ -6.62170326  -3.3851177    5.85671745   7.0236108   -7.49331458\n",
      "   0.36210486 -15.04975028  19.53423384  -3.44885674   3.02525766]\n"
     ]
    }
   ],
   "source": [
    "print (\"Scores\")\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_class = nn.predict(X_val[0])[0]\n",
    "predict_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original class\n",
    "y_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
