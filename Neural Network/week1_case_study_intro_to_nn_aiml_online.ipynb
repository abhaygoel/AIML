{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"week1_case_study_intro_to_nn_aiml_online.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"E8Cr_8mxAoXv","colab_type":"text"},"source":["# Neural network basics\n","----"]},{"cell_type":"markdown","metadata":{"id":"6vb8VyrqAoXy","colab_type":"text"},"source":["## Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?\n","The case study is from an open source dataset from Kaggle.\n","\n","Link to the Kaggle project site:\n","https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling"]},{"cell_type":"code","metadata":{"id":"9284-mcrB664","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"83f25c68-f90f-458a-b794-3d06bc1c71d7","executionInfo":{"status":"ok","timestamp":1574341643843,"user_tz":-330,"elapsed":839,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["%tensorflow_version 2.x"],"execution_count":1,"outputs":[{"output_type":"stream","text":["TensorFlow 2.x selected.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6TpNmIeYAoXz","colab_type":"text"},"source":["### Import libraries"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y0AS13202MCI","colab":{}},"source":["import pandas as pd\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from sklearn import model_selection\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n","from sklearn.metrics import confusion_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"UvmWcU4Y2MCO"},"source":["### Read the dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kybBDG1V2MCP","colab":{}},"source":["ds = pd.read_csv(\"Churn_Modelling.csv\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"rPnhjSxC2MCS","outputId":"3c390fce-a49d-42a7-f36a-db3e1694f1b0","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1574341665579,"user_tz":-330,"elapsed":1249,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["ds.head(10)"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>RowNumber</th>\n","      <th>CustomerId</th>\n","      <th>Surname</th>\n","      <th>CreditScore</th>\n","      <th>Geography</th>\n","      <th>Gender</th>\n","      <th>Age</th>\n","      <th>Tenure</th>\n","      <th>Balance</th>\n","      <th>NumOfProducts</th>\n","      <th>HasCrCard</th>\n","      <th>IsActiveMember</th>\n","      <th>EstimatedSalary</th>\n","      <th>Exited</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>15634602</td>\n","      <td>Hargrave</td>\n","      <td>619</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>2</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>101348.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>15647311</td>\n","      <td>Hill</td>\n","      <td>608</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>41</td>\n","      <td>1</td>\n","      <td>83807.86</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>112542.58</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>15619304</td>\n","      <td>Onio</td>\n","      <td>502</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>42</td>\n","      <td>8</td>\n","      <td>159660.80</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113931.57</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>15701354</td>\n","      <td>Boni</td>\n","      <td>699</td>\n","      <td>France</td>\n","      <td>Female</td>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>93826.63</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>15737888</td>\n","      <td>Mitchell</td>\n","      <td>850</td>\n","      <td>Spain</td>\n","      <td>Female</td>\n","      <td>43</td>\n","      <td>2</td>\n","      <td>125510.82</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>79084.10</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>15574012</td>\n","      <td>Chu</td>\n","      <td>645</td>\n","      <td>Spain</td>\n","      <td>Male</td>\n","      <td>44</td>\n","      <td>8</td>\n","      <td>113755.78</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>149756.71</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>15592531</td>\n","      <td>Bartlett</td>\n","      <td>822</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>50</td>\n","      <td>7</td>\n","      <td>0.00</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>10062.80</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>15656148</td>\n","      <td>Obinna</td>\n","      <td>376</td>\n","      <td>Germany</td>\n","      <td>Female</td>\n","      <td>29</td>\n","      <td>4</td>\n","      <td>115046.74</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>119346.88</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>15792365</td>\n","      <td>He</td>\n","      <td>501</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>44</td>\n","      <td>4</td>\n","      <td>142051.07</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>74940.50</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>15592389</td>\n","      <td>H?</td>\n","      <td>684</td>\n","      <td>France</td>\n","      <td>Male</td>\n","      <td>27</td>\n","      <td>2</td>\n","      <td>134603.88</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>71725.73</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n","0          1    15634602  Hargrave  ...               1       101348.88      1\n","1          2    15647311      Hill  ...               1       112542.58      0\n","2          3    15619304      Onio  ...               0       113931.57      1\n","3          4    15701354      Boni  ...               0        93826.63      0\n","4          5    15737888  Mitchell  ...               1        79084.10      0\n","5          6    15574012       Chu  ...               0       149756.71      1\n","6          7    15592531  Bartlett  ...               1        10062.80      0\n","7          8    15656148    Obinna  ...               0       119346.88      1\n","8          9    15792365        He  ...               1        74940.50      0\n","9         10    15592389        H?  ...               1        71725.73      0\n","\n","[10 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"E5FCBQRi2MCX"},"source":["### Drop the columns which are unique for all users like IDs"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zjYdG1Me2MCY","outputId":"eeb8885e-4dc1-4982-d482-c9d33b093423","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1574341667723,"user_tz":-330,"elapsed":847,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["ds['Geography'].value_counts()"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["France     5014\n","Germany    2509\n","Spain      2477\n","Name: Geography, dtype: int64"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"Vc0cjbTvAoYR","colab_type":"text"},"source":["### RowNumber, CustomerId, and Surname are unique hence we are dropping it"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Zi8q9XEv2MCf","colab":{}},"source":["ds = ds.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"coCQRBbm2MCj","outputId":"fc558973-7eff-4be6-98b8-b3b453d80ccf","colab":{"base_uri":"https://localhost:8080/","height":298},"executionInfo":{"status":"ok","timestamp":1574341671536,"user_tz":-330,"elapsed":899,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["ds.info()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 11 columns):\n","CreditScore        10000 non-null int64\n","Geography          10000 non-null object\n","Gender             10000 non-null object\n","Age                10000 non-null int64\n","Tenure             10000 non-null int64\n","Balance            10000 non-null float64\n","NumOfProducts      10000 non-null int64\n","HasCrCard          10000 non-null int64\n","IsActiveMember     10000 non-null int64\n","EstimatedSalary    10000 non-null float64\n","Exited             10000 non-null int64\n","dtypes: float64(2), int64(7), object(2)\n","memory usage: 859.5+ KB\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B8eWh6ox2MCp"},"source":["### Distinguish the feature and target set"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gY_wiurk2MCq","colab":{}},"source":["X = ds.iloc[:,0:10].values # Credit Score through Estimated Salary\n","y = ds.iloc[:,10].values # Exited"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oHlmxWHUAoYf","colab_type":"text"},"source":["### Encoding categorical (string based) data. Country: there are 3 options: France, Spain and Germany. This will convert those strings into scalar values for analysis."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jOroI5WQ2MCu","outputId":"c52bd6dc-a795-48e0-920e-08720baf4265","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1574341676125,"user_tz":-330,"elapsed":922,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["print(X[:8,1], '... will now become: ')\n","\n","label_X_country_encoder = LabelEncoder()\n","X[:,1] = label_X_country_encoder.fit_transform(X[:,1])\n","print(X[:8,1])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["['France' 'Spain' 'France' 'France' 'Spain' 'Spain' 'France' 'Germany'] ... will now become: \n","[0 2 0 0 2 2 0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VKStPf-YAoYj","colab_type":"text"},"source":["### We will do the same thing for gender. this will be binary in this dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e-twfXkV2MCz","outputId":"3a2ec25d-6f70-4f26-df04-ad1209b5a4dc","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1574341678200,"user_tz":-330,"elapsed":1178,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["print(X[:6,2], '... will now become: ')\n","\n","label_X_gender_encoder = LabelEncoder()\n","X[:,2] = label_X_gender_encoder.fit_transform(X[:,2])\n","print(X[:6,2])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["['Female' 'Female' 'Female' 'Female' 'Female' 'Male'] ... will now become: \n","[0 0 0 0 0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gkPMURW4AoYn","colab_type":"text"},"source":["### The Problem here is that we are treating the countries as one variable with ordinal values (0 < 1 < 2). Therefore, one way to get rid of that problem is to split the countries into respective dimensions. Gender does not need this as it is binary\n","\n","### Converting the string features into their own dimensions. Gender doesn't matter here because its binary"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h5xaQNH_2MC3","outputId":"3836f761-b3ca-4858-8802-e12bb6b32131","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1574341679671,"user_tz":-330,"elapsed":716,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["countryhotencoder = OneHotEncoder(categorical_features = [1]) # 1 is the country column\n","X = countryhotencoder.fit_transform(X).toarray()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n","If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n","In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n","  warnings.warn(msg, FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n","  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"wmwM4OOr2MC7","outputId":"655c64f8-ba2d-4c78-87da-8dd95697a0df","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1574341682109,"user_tz":-330,"elapsed":943,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["X.shape"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 12)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gG4wSXrB2MDC","outputId":"6bbd1607-69e4-417a-8d89-1a0e16514e9c","colab":{"base_uri":"https://localhost:8080/","height":246},"executionInfo":{"status":"ok","timestamp":1574341683487,"user_tz":-330,"elapsed":1120,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["X"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n","        1.0000000e+00, 1.0134888e+05],\n","       [0.0000000e+00, 0.0000000e+00, 1.0000000e+00, ..., 0.0000000e+00,\n","        1.0000000e+00, 1.1254258e+05],\n","       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n","        0.0000000e+00, 1.1393157e+05],\n","       ...,\n","       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n","        1.0000000e+00, 4.2085580e+04],\n","       [0.0000000e+00, 1.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n","        0.0000000e+00, 9.2888520e+04],\n","       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 1.0000000e+00,\n","        0.0000000e+00, 3.8190780e+04]])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"26EuNLE62MDH","colab":{}},"source":["# A 0 on two countries means that the country has to be the one variable which wasn't included \n","# This will save us from the problem of using too many dimensions\n","X = X[:,1:] # Got rid of Spain as a dimension."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5G-irNPm2MDL"},"source":["### Divide the data set into Train and test sets"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"G-JdmcgH2MDM","colab":{}},"source":["# Splitting the dataset into the Training and Testing set\n","X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 0)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"v59orwv_2MDQ"},"source":["### Normalize the train and test data"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8TqBQADf2MDR","colab":{}},"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc=StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h14ysgXo2MDU"},"source":["### Initialize & build the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lMyjKipO2MDV","colab":{}},"source":["# Initializing the ANN\n","classifier = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O3ecignQ2MDX","colab":{}},"source":["# The amount of nodes (dimensions) in hidden layer should be the average of input and output layers, in this case 6.\n","# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n","classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ov1vaKOW2MDa","colab":{}},"source":["#Add 1st hidden layer\n","classifier.add(Dense(6, activation='sigmoid', kernel_initializer='uniform'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Brkoooyr2MDd","colab":{}},"source":["# Adding the output layer\n","# Notice that we do not need to specify input dim. \n","# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n","# We use the sigmoid because we want probability outcomes\n","classifier.add(Dense(1, activation = 'sigmoid', kernel_initializer='uniform')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3IMvDnr92MDh","colab":{}},"source":["# Create optimizer with default learning rate\n","# sgd_optimizer = tf.keras.optimizers.SGD()\n","# Compile the model\n","classifier.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"E4UqHZj82MDj","outputId":"aee36983-24b2-4276-ea03-ce2d216a0265","colab":{"base_uri":"https://localhost:8080/","height":263},"executionInfo":{"status":"ok","timestamp":1574341702605,"user_tz":-330,"elapsed":706,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["classifier.summary()"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense (Dense)                (None, 6)                 72        \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 6)                 42        \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 7         \n","=================================================================\n","Total params: 121\n","Trainable params: 121\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NErktj342MDo","outputId":"22419916-5e77-4b48-eee9-d0276458b997","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1574341756129,"user_tz":-330,"elapsed":50621,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["classifier.fit(X_train, y_train,           \n","          validation_data=(X_test,y_test),\n","          epochs=100,\n","          batch_size=32)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Train on 8000 samples, validate on 2000 samples\n","Epoch 1/100\n","8000/8000 [==============================] - 2s 192us/sample - loss: 0.2120 - accuracy: 0.7620 - val_loss: 0.1844 - val_accuracy: 0.7975\n","Epoch 2/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1753 - accuracy: 0.7960 - val_loss: 0.1687 - val_accuracy: 0.7975\n","Epoch 3/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1667 - accuracy: 0.7960 - val_loss: 0.1642 - val_accuracy: 0.7975\n","Epoch 4/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1641 - accuracy: 0.7960 - val_loss: 0.1627 - val_accuracy: 0.7975\n","Epoch 5/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1631 - accuracy: 0.7960 - val_loss: 0.1621 - val_accuracy: 0.7975\n","Epoch 6/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1627 - accuracy: 0.7960 - val_loss: 0.1618 - val_accuracy: 0.7975\n","Epoch 7/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1626 - accuracy: 0.7960 - val_loss: 0.1617 - val_accuracy: 0.7975\n","Epoch 8/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1625 - accuracy: 0.7960 - val_loss: 0.1616 - val_accuracy: 0.7975\n","Epoch 9/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 10/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 11/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 12/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 13/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 14/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 15/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 16/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 17/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 18/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 19/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 20/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 21/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 22/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 23/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 24/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 25/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 26/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 27/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 28/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 29/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 30/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 31/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 32/100\n","8000/8000 [==============================] - 0s 58us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 33/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 34/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 35/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 36/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 37/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 38/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 39/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 40/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 41/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 42/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 43/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 44/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 45/100\n","8000/8000 [==============================] - 0s 58us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 46/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 47/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 48/100\n","8000/8000 [==============================] - 0s 57us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 49/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 50/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 51/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 52/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 53/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 54/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 55/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 56/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 57/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 58/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 59/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 60/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 61/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 62/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 63/100\n","8000/8000 [==============================] - 0s 58us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 64/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 65/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 66/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 67/100\n","8000/8000 [==============================] - 0s 58us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 68/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 69/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 70/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 71/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 72/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 73/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 74/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 75/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 76/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 77/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 78/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 79/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 80/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 81/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 82/100\n","8000/8000 [==============================] - 1s 66us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 83/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 84/100\n","8000/8000 [==============================] - 0s 59us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 85/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 86/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 87/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.1624 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 88/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 89/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 90/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1615 - val_accuracy: 0.7975\n","Epoch 91/100\n","8000/8000 [==============================] - 0s 58us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 92/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 93/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 94/100\n","8000/8000 [==============================] - 0s 57us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 95/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 96/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 97/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 98/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 99/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n","Epoch 100/100\n","8000/8000 [==============================] - 1s 67us/sample - loss: 0.1623 - accuracy: 0.7960 - val_loss: 0.1614 - val_accuracy: 0.7975\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f948f48e048>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aXUi_lqe2MDs"},"source":["### Predict the results using 0.5 as a threshold"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GxXO6--h2MDt","outputId":"86da3cb7-2c20-46da-9829-366362f741e5","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1574341756519,"user_tz":-330,"elapsed":29251,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["y_pred = classifier.predict(X_test)\n","print(y_pred)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[[0.20410725]\n"," [0.2040019 ]\n"," [0.20410031]\n"," ...\n"," [0.20384255]\n"," [0.20396742]\n"," [0.20380473]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EIPDxM892MDw","outputId":"6e2c9752-545b-48e3-c785-793825ebf734","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1574341756521,"user_tz":-330,"elapsed":27600,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["# To use the confusion Matrix, we need to convert the probabilities that a customer will leave the bank into the form true or false. \n","# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.\n","y_pred = (y_pred > 0.5)\n","print(y_pred)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["[[False]\n"," [False]\n"," [False]\n"," ...\n"," [False]\n"," [False]\n"," [False]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VkX2OXIb2MD1"},"source":["### Print the Accuracy score and confusion matrix"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5Bx-Xgej2MD1","outputId":"011d6e16-1615-49ee-df88-2ec841f51186","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1574341756522,"user_tz":-330,"elapsed":23029,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["cm1 = confusion_matrix(y_test, y_pred)\n","print(cm1)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["[[1595    0]\n"," [ 405    0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1nwXHTVc2MD4","outputId":"530a849f-2644-4be4-bbc6-10374c4f7173","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1574341756523,"user_tz":-330,"elapsed":21830,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["accuracy_model1 = ((cm1[0][0]+cm1[1][1])*100)/(cm1[0][0]+cm1[1][1]+cm1[0][1]+cm1[1][0])\n","print (accuracy_model1, '% of testing data was classified correctly')"],"execution_count":27,"outputs":[{"output_type":"stream","text":["79.75 % of testing data was classified correctly\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ITHuG0BY2MD7"},"source":["### Optimize the model"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ilZJGtVw2MD8"},"source":["Some important parameters to look out for while optimizing neural networks are:\n","\n","-Type of architecture\n","\n","-Number of Layers\n","\n","-Number of Neurons in a layer\n","\n","-Regularization parameters\n","\n","-Learning Rate\n","\n","-Type of optimization / backpropagation technique to use\n","\n","-Dropout rate\n","\n","-Weight sharing"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NfcLaivq2MD9"},"source":["#### Number of Layers:\n","We will keep it similar to the above model so that we can compare the accuracy.\n","1 hidden layer.\n","\n","#### Activation:\n","input layer: relu becasue we are in an input layer. uses the ReLu activation function for  ϕ\n","output layer: sigmoid becasue we are in an output layer. uses the Sigmoid activation function for  ϕ . This is used instead of the ReLu function becasue it generates probabilities for the outcome. We want the probability that each customer leaves the bank.\n","\n","#### Type of optimization / backpropagation technique to use: \n","We will use Adam. Adam is a very efficeint variation of Stochastic Gradient Descent. For Adam and its variant, learning rate or the decay rate does not really matter too much.\n","\n","#### Learning Rate:\n","default learning rate 0.001.\n","\n","#### Number of Neurons in a layer:\n","We will keep it 6 as per our initial calculation above.\n","\n","#### Weight sharing / kernel_initializer: \n","uniform the distribution with which we randomly initialize weights for the nodes in this layer.\n","\n","#### Loss:\n","loss: binary_crossentropy This is the loss function used within adam. This should be the logarthmic loss. If our dependent (output variable) is Binary, it is binary_crossentropy. If Categorical, then it is called categorical_crossentropy\n","\n","### Rebuilding the model using these optimised parameters"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TYBOVfnW2MEB","colab":{}},"source":["# Initializing the ANN\n","classifier = Sequential()\n","# This adds the input layer (by specifying input dimension) AND the first hidden layer (units)\n","classifier.add(Dense(activation = 'relu', input_dim = 11, units=6, kernel_initializer='uniform'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1CAa_tm82MEF","colab":{}},"source":["# Adding the hidden layer\n","# Notice that we do not need to specify input dim. \n","classifier.add(Dense(activation = 'relu', units=6, kernel_initializer='uniform')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"AzZPPFIZ2MEI","colab":{}},"source":["# Adding the output layer\n","# Notice that we do not need to specify input dim. \n","# we have an output of 1 node, which is the the desired dimensions of our output (stay with the bank or not)\n","# We use the sigmoid because we want probability outcomes\n","classifier.add(Dense(activation = 'sigmoid', units=1, kernel_initializer='uniform')) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"7PNJ1TPS2MEK","colab":{}},"source":["classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NbUkhk902MEM","outputId":"21005817-865d-457d-c712-f9f9a62bf0be","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1574341809651,"user_tz":-330,"elapsed":53083,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["classifier.fit(X_train, y_train,           \n","          validation_data=(X_test,y_test),\n","          epochs=100,\n","          batch_size=32)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Train on 8000 samples, validate on 2000 samples\n","Epoch 1/100\n","8000/8000 [==============================] - 1s 138us/sample - loss: 0.5562 - accuracy: 0.7960 - val_loss: 0.4379 - val_accuracy: 0.7975\n","Epoch 2/100\n","8000/8000 [==============================] - 1s 69us/sample - loss: 0.4370 - accuracy: 0.7960 - val_loss: 0.4305 - val_accuracy: 0.7975\n","Epoch 3/100\n","8000/8000 [==============================] - 1s 75us/sample - loss: 0.4312 - accuracy: 0.7960 - val_loss: 0.4276 - val_accuracy: 0.7975\n","Epoch 4/100\n","8000/8000 [==============================] - 1s 67us/sample - loss: 0.4283 - accuracy: 0.7960 - val_loss: 0.4249 - val_accuracy: 0.7975\n","Epoch 5/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4257 - accuracy: 0.7960 - val_loss: 0.4228 - val_accuracy: 0.7975\n","Epoch 6/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4224 - accuracy: 0.7960 - val_loss: 0.4198 - val_accuracy: 0.7975\n","Epoch 7/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4204 - accuracy: 0.8114 - val_loss: 0.4166 - val_accuracy: 0.8270\n","Epoch 8/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4182 - accuracy: 0.8219 - val_loss: 0.4150 - val_accuracy: 0.8310\n","Epoch 9/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4168 - accuracy: 0.8230 - val_loss: 0.4149 - val_accuracy: 0.8340\n","Epoch 10/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4159 - accuracy: 0.8260 - val_loss: 0.4132 - val_accuracy: 0.8365\n","Epoch 11/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4148 - accuracy: 0.8290 - val_loss: 0.4116 - val_accuracy: 0.8390\n","Epoch 12/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4138 - accuracy: 0.8282 - val_loss: 0.4099 - val_accuracy: 0.8365\n","Epoch 13/100\n","8000/8000 [==============================] - 1s 66us/sample - loss: 0.4129 - accuracy: 0.8319 - val_loss: 0.4099 - val_accuracy: 0.8370\n","Epoch 14/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4121 - accuracy: 0.8321 - val_loss: 0.4088 - val_accuracy: 0.8370\n","Epoch 15/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4112 - accuracy: 0.8334 - val_loss: 0.4093 - val_accuracy: 0.8385\n","Epoch 16/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4107 - accuracy: 0.8339 - val_loss: 0.4065 - val_accuracy: 0.8390\n","Epoch 17/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4100 - accuracy: 0.8332 - val_loss: 0.4059 - val_accuracy: 0.8385\n","Epoch 18/100\n","8000/8000 [==============================] - 1s 66us/sample - loss: 0.4095 - accuracy: 0.8345 - val_loss: 0.4057 - val_accuracy: 0.8400\n","Epoch 19/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4088 - accuracy: 0.8338 - val_loss: 0.4052 - val_accuracy: 0.8375\n","Epoch 20/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4082 - accuracy: 0.8341 - val_loss: 0.4044 - val_accuracy: 0.8395\n","Epoch 21/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4074 - accuracy: 0.8341 - val_loss: 0.4025 - val_accuracy: 0.8400\n","Epoch 22/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4070 - accuracy: 0.8344 - val_loss: 0.4018 - val_accuracy: 0.8390\n","Epoch 23/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4062 - accuracy: 0.8340 - val_loss: 0.4023 - val_accuracy: 0.8395\n","Epoch 24/100\n","8000/8000 [==============================] - 1s 67us/sample - loss: 0.4057 - accuracy: 0.8350 - val_loss: 0.4033 - val_accuracy: 0.8390\n","Epoch 25/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4056 - accuracy: 0.8356 - val_loss: 0.4003 - val_accuracy: 0.8385\n","Epoch 26/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4052 - accuracy: 0.8345 - val_loss: 0.4017 - val_accuracy: 0.8395\n","Epoch 27/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4047 - accuracy: 0.8359 - val_loss: 0.4009 - val_accuracy: 0.8395\n","Epoch 28/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4048 - accuracy: 0.8347 - val_loss: 0.4006 - val_accuracy: 0.8395\n","Epoch 29/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4042 - accuracy: 0.8359 - val_loss: 0.4005 - val_accuracy: 0.8385\n","Epoch 30/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4041 - accuracy: 0.8344 - val_loss: 0.3991 - val_accuracy: 0.8380\n","Epoch 31/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4035 - accuracy: 0.8355 - val_loss: 0.4011 - val_accuracy: 0.8405\n","Epoch 32/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4034 - accuracy: 0.8351 - val_loss: 0.3991 - val_accuracy: 0.8390\n","Epoch 33/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4035 - accuracy: 0.8364 - val_loss: 0.3992 - val_accuracy: 0.8400\n","Epoch 34/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4033 - accuracy: 0.8359 - val_loss: 0.4001 - val_accuracy: 0.8390\n","Epoch 35/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4031 - accuracy: 0.8366 - val_loss: 0.3984 - val_accuracy: 0.8400\n","Epoch 36/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4027 - accuracy: 0.8360 - val_loss: 0.3996 - val_accuracy: 0.8395\n","Epoch 37/100\n","8000/8000 [==============================] - 1s 66us/sample - loss: 0.4029 - accuracy: 0.8356 - val_loss: 0.3977 - val_accuracy: 0.8395\n","Epoch 38/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4026 - accuracy: 0.8342 - val_loss: 0.3997 - val_accuracy: 0.8415\n","Epoch 39/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4027 - accuracy: 0.8365 - val_loss: 0.3991 - val_accuracy: 0.8420\n","Epoch 40/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4021 - accuracy: 0.8367 - val_loss: 0.3990 - val_accuracy: 0.8410\n","Epoch 41/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4023 - accuracy: 0.8346 - val_loss: 0.3981 - val_accuracy: 0.8380\n","Epoch 42/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4021 - accuracy: 0.8350 - val_loss: 0.3975 - val_accuracy: 0.8390\n","Epoch 43/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4018 - accuracy: 0.8349 - val_loss: 0.3999 - val_accuracy: 0.8390\n","Epoch 44/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.4017 - accuracy: 0.8356 - val_loss: 0.3994 - val_accuracy: 0.8435\n","Epoch 45/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4018 - accuracy: 0.8363 - val_loss: 0.3987 - val_accuracy: 0.8420\n","Epoch 46/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4017 - accuracy: 0.8361 - val_loss: 0.3970 - val_accuracy: 0.8420\n","Epoch 47/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4015 - accuracy: 0.8349 - val_loss: 0.3980 - val_accuracy: 0.8430\n","Epoch 48/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4013 - accuracy: 0.8361 - val_loss: 0.3973 - val_accuracy: 0.8405\n","Epoch 49/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4011 - accuracy: 0.8360 - val_loss: 0.3975 - val_accuracy: 0.8395\n","Epoch 50/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4011 - accuracy: 0.8342 - val_loss: 0.3975 - val_accuracy: 0.8400\n","Epoch 51/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4012 - accuracy: 0.8359 - val_loss: 0.3982 - val_accuracy: 0.8405\n","Epoch 52/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4012 - accuracy: 0.8351 - val_loss: 0.3983 - val_accuracy: 0.8420\n","Epoch 53/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4011 - accuracy: 0.8355 - val_loss: 0.3977 - val_accuracy: 0.8435\n","Epoch 54/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4007 - accuracy: 0.8364 - val_loss: 0.3970 - val_accuracy: 0.8400\n","Epoch 55/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4009 - accuracy: 0.8354 - val_loss: 0.3978 - val_accuracy: 0.8410\n","Epoch 56/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4007 - accuracy: 0.8346 - val_loss: 0.3979 - val_accuracy: 0.8415\n","Epoch 57/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4005 - accuracy: 0.8353 - val_loss: 0.3972 - val_accuracy: 0.8395\n","Epoch 58/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4004 - accuracy: 0.8351 - val_loss: 0.3979 - val_accuracy: 0.8420\n","Epoch 59/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4005 - accuracy: 0.8353 - val_loss: 0.3966 - val_accuracy: 0.8400\n","Epoch 60/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.4012 - accuracy: 0.8364 - val_loss: 0.3970 - val_accuracy: 0.8430\n","Epoch 61/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4004 - accuracy: 0.8344 - val_loss: 0.3992 - val_accuracy: 0.8425\n","Epoch 62/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4004 - accuracy: 0.8361 - val_loss: 0.3988 - val_accuracy: 0.8435\n","Epoch 63/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.4002 - accuracy: 0.8366 - val_loss: 0.3978 - val_accuracy: 0.8415\n","Epoch 64/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4004 - accuracy: 0.8340 - val_loss: 0.3974 - val_accuracy: 0.8390\n","Epoch 65/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4002 - accuracy: 0.8350 - val_loss: 0.3974 - val_accuracy: 0.8415\n","Epoch 66/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.4004 - accuracy: 0.8349 - val_loss: 0.3977 - val_accuracy: 0.8425\n","Epoch 67/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4000 - accuracy: 0.8353 - val_loss: 0.4002 - val_accuracy: 0.8400\n","Epoch 68/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4001 - accuracy: 0.8365 - val_loss: 0.4021 - val_accuracy: 0.8420\n","Epoch 69/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4002 - accuracy: 0.8356 - val_loss: 0.3973 - val_accuracy: 0.8410\n","Epoch 70/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4000 - accuracy: 0.8347 - val_loss: 0.3979 - val_accuracy: 0.8410\n","Epoch 71/100\n","8000/8000 [==============================] - 0s 60us/sample - loss: 0.4002 - accuracy: 0.8346 - val_loss: 0.3971 - val_accuracy: 0.8430\n","Epoch 72/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.4000 - accuracy: 0.8349 - val_loss: 0.3976 - val_accuracy: 0.8410\n","Epoch 73/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.3996 - accuracy: 0.8363 - val_loss: 0.3971 - val_accuracy: 0.8410\n","Epoch 74/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.4001 - accuracy: 0.8364 - val_loss: 0.3985 - val_accuracy: 0.8420\n","Epoch 75/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.3999 - accuracy: 0.8369 - val_loss: 0.3985 - val_accuracy: 0.8445\n","Epoch 76/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.3997 - accuracy: 0.8349 - val_loss: 0.3989 - val_accuracy: 0.8425\n","Epoch 77/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.3999 - accuracy: 0.8361 - val_loss: 0.3978 - val_accuracy: 0.8405\n","Epoch 78/100\n","8000/8000 [==============================] - 1s 67us/sample - loss: 0.3998 - accuracy: 0.8359 - val_loss: 0.3974 - val_accuracy: 0.8410\n","Epoch 79/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3994 - accuracy: 0.8347 - val_loss: 0.3996 - val_accuracy: 0.8430\n","Epoch 80/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3996 - accuracy: 0.8359 - val_loss: 0.3985 - val_accuracy: 0.8435\n","Epoch 81/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.3998 - accuracy: 0.8367 - val_loss: 0.4003 - val_accuracy: 0.8410\n","Epoch 82/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.3993 - accuracy: 0.8353 - val_loss: 0.4001 - val_accuracy: 0.8420\n","Epoch 83/100\n","8000/8000 [==============================] - 1s 63us/sample - loss: 0.3998 - accuracy: 0.8357 - val_loss: 0.3976 - val_accuracy: 0.8405\n","Epoch 84/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3998 - accuracy: 0.8361 - val_loss: 0.3986 - val_accuracy: 0.8405\n","Epoch 85/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.3997 - accuracy: 0.8353 - val_loss: 0.3980 - val_accuracy: 0.8425\n","Epoch 86/100\n","8000/8000 [==============================] - 1s 68us/sample - loss: 0.3995 - accuracy: 0.8360 - val_loss: 0.3980 - val_accuracy: 0.8430\n","Epoch 87/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3993 - accuracy: 0.8366 - val_loss: 0.3976 - val_accuracy: 0.8370\n","Epoch 88/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.3998 - accuracy: 0.8356 - val_loss: 0.3982 - val_accuracy: 0.8400\n","Epoch 89/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.3996 - accuracy: 0.8354 - val_loss: 0.3999 - val_accuracy: 0.8420\n","Epoch 90/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3994 - accuracy: 0.8365 - val_loss: 0.3999 - val_accuracy: 0.8425\n","Epoch 91/100\n","8000/8000 [==============================] - 0s 62us/sample - loss: 0.3991 - accuracy: 0.8359 - val_loss: 0.3980 - val_accuracy: 0.8430\n","Epoch 92/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.3994 - accuracy: 0.8356 - val_loss: 0.3988 - val_accuracy: 0.8415\n","Epoch 93/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3992 - accuracy: 0.8357 - val_loss: 0.3978 - val_accuracy: 0.8420\n","Epoch 94/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.3992 - accuracy: 0.8355 - val_loss: 0.3975 - val_accuracy: 0.8430\n","Epoch 95/100\n","8000/8000 [==============================] - 0s 61us/sample - loss: 0.3990 - accuracy: 0.8365 - val_loss: 0.3978 - val_accuracy: 0.8395\n","Epoch 96/100\n","8000/8000 [==============================] - 1s 65us/sample - loss: 0.3995 - accuracy: 0.8351 - val_loss: 0.3968 - val_accuracy: 0.8425\n","Epoch 97/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3992 - accuracy: 0.8351 - val_loss: 0.3981 - val_accuracy: 0.8400\n","Epoch 98/100\n","8000/8000 [==============================] - 1s 66us/sample - loss: 0.3991 - accuracy: 0.8355 - val_loss: 0.3989 - val_accuracy: 0.8430\n","Epoch 99/100\n","8000/8000 [==============================] - 1s 66us/sample - loss: 0.3992 - accuracy: 0.8369 - val_loss: 0.3967 - val_accuracy: 0.8425\n","Epoch 100/100\n","8000/8000 [==============================] - 1s 64us/sample - loss: 0.3991 - accuracy: 0.8367 - val_loss: 0.3990 - val_accuracy: 0.8405\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f948e25fac8>"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qbkNCKVX2MEP"},"source":["### Predict the results using 0.5 as a threshold"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qwMd3oJO2MEQ","outputId":"db78d7d8-ca8b-4666-9412-11829ae5c6aa","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1574341809656,"user_tz":-330,"elapsed":53067,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["y_pred = classifier.predict(X_test)\n","print(y_pred)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[[0.21548188]\n"," [0.3674677 ]\n"," [0.16310653]\n"," ...\n"," [0.22479099]\n"," [0.15512791]\n"," [0.12217143]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ppMSEGmq2MET","outputId":"bee8b07c-6f73-4ff1-832f-420570bf0905","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1574341809657,"user_tz":-330,"elapsed":53053,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["# To use the confusion Matrix, we need to convert the probabilities that a customer will leave the bank into the form true or false. \n","# So we will use the cutoff value 0.5 to indicate whether they are likely to exit or not.\n","y_pred = (y_pred > 0.5)\n","print(y_pred)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["[[False]\n"," [False]\n"," [False]\n"," ...\n"," [False]\n"," [False]\n"," [False]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"c1jh390C2MEW"},"source":["### Print the Accuracy score and confusion matrix"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3w6XYuiN2MEX","outputId":"ee4caa83-3565-46be-903e-b8bbc4bff54e","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1574341809658,"user_tz":-330,"elapsed":53041,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["cm2 = confusion_matrix(y_test, y_pred)\n","print(cm2)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["[[1542   53]\n"," [ 266  139]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lOklmKrD2MEf","outputId":"1a12256a-25ce-4112-b54e-3bfad5dfd166","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1574341809659,"user_tz":-330,"elapsed":52606,"user":{"displayName":"Suryansh Sharma","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBy1CGO0PDyRG1nsJ6rDaUXBg-h18OkEJ86htszrw=s64","userId":"03232072030227591914"}}},"source":["accuracy_model2 = ((cm2[0][0]+cm2[1][1])*100)/(cm2[0][0]+cm2[1][1]+cm2[0][1]+cm2[1][0])\n","print (accuracy_model2, '% of testing data was classified correctly')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["84.05 % of testing data was classified correctly\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4ztRo0AeAoaM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}